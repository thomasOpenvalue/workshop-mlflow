{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Workshop MLflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__*Objectives*__\n",
    "\n",
    "Use **ML Flow Tracking** to follow a model key metrics\n",
    "\n",
    "__*Steps*__\n",
    "\n",
    "1. Import Libs\n",
    "2. Load cleaned data\n",
    "    * Load CSV\n",
    "    * Short Data description\n",
    "3. Understand the data\n",
    "    * Pandas Profiling\n",
    "4. Machine Learning\n",
    "    * Preprocess\n",
    "    * Metrics\n",
    "    * Models\n",
    "    * Results\n",
    "5. MLFlow\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-09T06:48:53.403325Z",
     "start_time": "2019-04-09T06:48:53.399643Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/fontaine/anaconda3/envs/workshop-mlflow/lib/python3.7/site-packages/mlflow/utils/environment.py:26: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\n",
      "  env = yaml.load(_conda_header)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas_profiling as pdp\n",
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-09T06:20:48.484408Z",
     "start_time": "2019-04-09T06:20:48.481622Z"
    }
   },
   "outputs": [],
   "source": [
    "# Display all the columns of Pandas Dataframe\n",
    "pd.options.display.max_columns = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-09T06:22:34.137997Z",
     "start_time": "2019-04-09T06:22:33.960217Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nb observations: 19735 - nb features: 29\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>Appliances</th>\n",
       "      <th>lights</th>\n",
       "      <th>T1</th>\n",
       "      <th>RH_1</th>\n",
       "      <th>T2</th>\n",
       "      <th>RH_2</th>\n",
       "      <th>T3</th>\n",
       "      <th>RH_3</th>\n",
       "      <th>T4</th>\n",
       "      <th>RH_4</th>\n",
       "      <th>T5</th>\n",
       "      <th>RH_5</th>\n",
       "      <th>T6</th>\n",
       "      <th>RH_6</th>\n",
       "      <th>T7</th>\n",
       "      <th>RH_7</th>\n",
       "      <th>T8</th>\n",
       "      <th>RH_8</th>\n",
       "      <th>T9</th>\n",
       "      <th>RH_9</th>\n",
       "      <th>T_out</th>\n",
       "      <th>Press_mm_hg</th>\n",
       "      <th>RH_out</th>\n",
       "      <th>Windspeed</th>\n",
       "      <th>Visibility</th>\n",
       "      <th>Tdewpoint</th>\n",
       "      <th>rv1</th>\n",
       "      <th>rv2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2016-01-11 17:00:00</td>\n",
       "      <td>60</td>\n",
       "      <td>30</td>\n",
       "      <td>19.89</td>\n",
       "      <td>47.596667</td>\n",
       "      <td>19.2</td>\n",
       "      <td>44.790000</td>\n",
       "      <td>19.79</td>\n",
       "      <td>44.730000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>45.566667</td>\n",
       "      <td>17.166667</td>\n",
       "      <td>55.20</td>\n",
       "      <td>7.026667</td>\n",
       "      <td>84.256667</td>\n",
       "      <td>17.200000</td>\n",
       "      <td>41.626667</td>\n",
       "      <td>18.2</td>\n",
       "      <td>48.900000</td>\n",
       "      <td>17.033333</td>\n",
       "      <td>45.53</td>\n",
       "      <td>6.600000</td>\n",
       "      <td>733.5</td>\n",
       "      <td>92.0</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>63.000000</td>\n",
       "      <td>5.3</td>\n",
       "      <td>13.275433</td>\n",
       "      <td>13.275433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2016-01-11 17:10:00</td>\n",
       "      <td>60</td>\n",
       "      <td>30</td>\n",
       "      <td>19.89</td>\n",
       "      <td>46.693333</td>\n",
       "      <td>19.2</td>\n",
       "      <td>44.722500</td>\n",
       "      <td>19.79</td>\n",
       "      <td>44.790000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>45.992500</td>\n",
       "      <td>17.166667</td>\n",
       "      <td>55.20</td>\n",
       "      <td>6.833333</td>\n",
       "      <td>84.063333</td>\n",
       "      <td>17.200000</td>\n",
       "      <td>41.560000</td>\n",
       "      <td>18.2</td>\n",
       "      <td>48.863333</td>\n",
       "      <td>17.066667</td>\n",
       "      <td>45.56</td>\n",
       "      <td>6.483333</td>\n",
       "      <td>733.6</td>\n",
       "      <td>92.0</td>\n",
       "      <td>6.666667</td>\n",
       "      <td>59.166667</td>\n",
       "      <td>5.2</td>\n",
       "      <td>18.606195</td>\n",
       "      <td>18.606195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2016-01-11 17:20:00</td>\n",
       "      <td>50</td>\n",
       "      <td>30</td>\n",
       "      <td>19.89</td>\n",
       "      <td>46.300000</td>\n",
       "      <td>19.2</td>\n",
       "      <td>44.626667</td>\n",
       "      <td>19.79</td>\n",
       "      <td>44.933333</td>\n",
       "      <td>18.926667</td>\n",
       "      <td>45.890000</td>\n",
       "      <td>17.166667</td>\n",
       "      <td>55.09</td>\n",
       "      <td>6.560000</td>\n",
       "      <td>83.156667</td>\n",
       "      <td>17.200000</td>\n",
       "      <td>41.433333</td>\n",
       "      <td>18.2</td>\n",
       "      <td>48.730000</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>45.50</td>\n",
       "      <td>6.366667</td>\n",
       "      <td>733.7</td>\n",
       "      <td>92.0</td>\n",
       "      <td>6.333333</td>\n",
       "      <td>55.333333</td>\n",
       "      <td>5.1</td>\n",
       "      <td>28.642668</td>\n",
       "      <td>28.642668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2016-01-11 17:30:00</td>\n",
       "      <td>50</td>\n",
       "      <td>40</td>\n",
       "      <td>19.89</td>\n",
       "      <td>46.066667</td>\n",
       "      <td>19.2</td>\n",
       "      <td>44.590000</td>\n",
       "      <td>19.79</td>\n",
       "      <td>45.000000</td>\n",
       "      <td>18.890000</td>\n",
       "      <td>45.723333</td>\n",
       "      <td>17.166667</td>\n",
       "      <td>55.09</td>\n",
       "      <td>6.433333</td>\n",
       "      <td>83.423333</td>\n",
       "      <td>17.133333</td>\n",
       "      <td>41.290000</td>\n",
       "      <td>18.1</td>\n",
       "      <td>48.590000</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>45.40</td>\n",
       "      <td>6.250000</td>\n",
       "      <td>733.8</td>\n",
       "      <td>92.0</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>51.500000</td>\n",
       "      <td>5.0</td>\n",
       "      <td>45.410389</td>\n",
       "      <td>45.410389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2016-01-11 17:40:00</td>\n",
       "      <td>60</td>\n",
       "      <td>40</td>\n",
       "      <td>19.89</td>\n",
       "      <td>46.333333</td>\n",
       "      <td>19.2</td>\n",
       "      <td>44.530000</td>\n",
       "      <td>19.79</td>\n",
       "      <td>45.000000</td>\n",
       "      <td>18.890000</td>\n",
       "      <td>45.530000</td>\n",
       "      <td>17.200000</td>\n",
       "      <td>55.09</td>\n",
       "      <td>6.366667</td>\n",
       "      <td>84.893333</td>\n",
       "      <td>17.200000</td>\n",
       "      <td>41.230000</td>\n",
       "      <td>18.1</td>\n",
       "      <td>48.590000</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>45.40</td>\n",
       "      <td>6.133333</td>\n",
       "      <td>733.9</td>\n",
       "      <td>92.0</td>\n",
       "      <td>5.666667</td>\n",
       "      <td>47.666667</td>\n",
       "      <td>4.9</td>\n",
       "      <td>10.084097</td>\n",
       "      <td>10.084097</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  date  Appliances  lights     T1       RH_1    T2       RH_2  \\\n",
       "0  2016-01-11 17:00:00          60      30  19.89  47.596667  19.2  44.790000   \n",
       "1  2016-01-11 17:10:00          60      30  19.89  46.693333  19.2  44.722500   \n",
       "2  2016-01-11 17:20:00          50      30  19.89  46.300000  19.2  44.626667   \n",
       "3  2016-01-11 17:30:00          50      40  19.89  46.066667  19.2  44.590000   \n",
       "4  2016-01-11 17:40:00          60      40  19.89  46.333333  19.2  44.530000   \n",
       "\n",
       "      T3       RH_3         T4       RH_4         T5   RH_5        T6  \\\n",
       "0  19.79  44.730000  19.000000  45.566667  17.166667  55.20  7.026667   \n",
       "1  19.79  44.790000  19.000000  45.992500  17.166667  55.20  6.833333   \n",
       "2  19.79  44.933333  18.926667  45.890000  17.166667  55.09  6.560000   \n",
       "3  19.79  45.000000  18.890000  45.723333  17.166667  55.09  6.433333   \n",
       "4  19.79  45.000000  18.890000  45.530000  17.200000  55.09  6.366667   \n",
       "\n",
       "        RH_6         T7       RH_7    T8       RH_8         T9   RH_9  \\\n",
       "0  84.256667  17.200000  41.626667  18.2  48.900000  17.033333  45.53   \n",
       "1  84.063333  17.200000  41.560000  18.2  48.863333  17.066667  45.56   \n",
       "2  83.156667  17.200000  41.433333  18.2  48.730000  17.000000  45.50   \n",
       "3  83.423333  17.133333  41.290000  18.1  48.590000  17.000000  45.40   \n",
       "4  84.893333  17.200000  41.230000  18.1  48.590000  17.000000  45.40   \n",
       "\n",
       "      T_out  Press_mm_hg  RH_out  Windspeed  Visibility  Tdewpoint        rv1  \\\n",
       "0  6.600000        733.5    92.0   7.000000   63.000000        5.3  13.275433   \n",
       "1  6.483333        733.6    92.0   6.666667   59.166667        5.2  18.606195   \n",
       "2  6.366667        733.7    92.0   6.333333   55.333333        5.1  28.642668   \n",
       "3  6.250000        733.8    92.0   6.000000   51.500000        5.0  45.410389   \n",
       "4  6.133333        733.9    92.0   5.666667   47.666667        4.9  10.084097   \n",
       "\n",
       "         rv2  \n",
       "0  13.275433  \n",
       "1  18.606195  \n",
       "2  28.642668  \n",
       "3  45.410389  \n",
       "4  10.084097  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_all = pd.read_csv('./data/energydata_complete.csv')\n",
    "\n",
    "print('nb observations: {} - nb features: {}'.format(*df_all.shape))\n",
    "df_all.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Information about the data set\n",
    "\n",
    "Column Name  | Description | Unit\n",
    "------------ | ----------- | -----------\n",
    "date | year-month-day hour:minute:second | \n",
    "lights | energy use of light fixtures the house | Wh \n",
    "T1 | Temperature in kitchen area, | Celsius \n",
    "RH_1 | Humidity in kitchen area, | % \n",
    "T2 | Temperature in living room area, | Celsius \n",
    "RH_2 | Humidity in living room area, | % \n",
    "T3 | Temperature in laundry room area \n",
    "RH_3 | Humidity in laundry room area, | % \n",
    "T4 | Temperature in office room, | Celsius \n",
    "RH_4 | Humidity in office room, | % \n",
    "T5 | Temperature in bathroom, | Celsius \n",
    "RH_5 | Humidity in bathroom, | % \n",
    "T6 | Temperature outside the building (north side), | Celsius \n",
    "RH_6 | Humidity outside the building (north side), | % \n",
    "T7 | Temperature in ironing room , | Celsius \n",
    "RH_7 | Humidity in ironing room, | % \n",
    "T8 | Temperature in teenager room 2, | Celsius \n",
    "RH_8 | Humidity in teenager room 2, | % \n",
    "T9 | Temperature in parents room, | Celsius \n",
    "RH_9 | Humidity in parents room, | % \n",
    "To | Temperature outside (from Chievres weather station), | Celsius \n",
    "Pressure | (from Chievres weather station), | mm Hg \n",
    "RH_out | Humidity outside (from Chievres weather station), | % \n",
    "Wind speed | (from Chievres weather station), | m/s \n",
    "Visibility | (from Chievres weather station), | km \n",
    "Tdewpoint | (from Chievres weather station), Â°C \n",
    "rv1 | Random variable 1, nondimensional \n",
    "rv2 | Random variable 2, nondimensional \n",
    "------------ | ----------- | -----------\n",
    "Appliances | energy use | Wh\n",
    "\n",
    "\n",
    "We will create a report named `report-all-data.html` in the repo `./analysis`.\n",
    "This report helps us to understand all distribution and correlation in the data set. You can go into that repo and open it in your browser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-09T06:33:19.056094Z",
     "start_time": "2019-04-09T06:33:19.039473Z"
    }
   },
   "outputs": [],
   "source": [
    "# Just Random variable for robustness\n",
    "df_all.drop(columns=['date', 'rv1', 'rv2'], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get report analysis : [PandasProfiling](https://github.com/pandas-profiling/pandas-profiling)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-09T06:55:18.315576Z",
     "start_time": "2019-04-09T06:55:18.312182Z"
    }
   },
   "outputs": [],
   "source": [
    "if not os.path.exists(\"./analysis\"):\n",
    "    os.mkdir(\"./analysis\") # Create repo because does not exist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-09T06:55:25.378775Z",
     "start_time": "2019-04-09T06:55:21.706428Z"
    }
   },
   "outputs": [],
   "source": [
    "profile = pdp.ProfileReport(df_all)\n",
    "profile.to_file(outputfile=\"./analysis/report-all-data.html\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's have a look at the created [report](./analysis/report-all-data.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's talk about Machine Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__*What is the objective of the model?*__\n",
    "\n",
    "=> Predict the Quantity of Energy used\n",
    "\n",
    "We will use a first ML model to see what kind of information we need to record to (for example) evaluate the capacity of the model, if we suffer from overfitting or underfitting etc. From that we will understand why `mlflow` is a great tool for tracking metrics and save artifacts."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-09T07:21:30.170761Z",
     "start_time": "2019-04-09T07:21:30.142566Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "target_column = \"Appliances\" # \"y\"\n",
    "\n",
    "train, test = train_test_split(df_all) # default test size 1/4\n",
    "\n",
    "train_x = train.drop([target_column], axis=1)\n",
    "test_x = test.drop([target_column], axis=1)\n",
    "train_y = train[target_column]\n",
    "test_y = test[target_column]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-09T07:23:17.162199Z",
     "start_time": "2019-04-09T07:23:17.159463Z"
    }
   },
   "source": [
    "## Metrics to evaluate the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-09T07:24:40.874216Z",
     "start_time": "2019-04-09T07:24:40.867439Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "\n",
    "def eval_metrics(actual, pred):\n",
    "    rmse = np.sqrt(mean_squared_error(actual, pred))\n",
    "    mae = mean_absolute_error(actual, pred)\n",
    "    r2 = r2_score(actual, pred)\n",
    "    return rmse, mae, r2\n",
    "\n",
    "\n",
    "def scatter_plot_result(y_actual, y_pred, model_name):\n",
    "    plt.scatter(y_actual, y_pred)\n",
    "    \n",
    "    plt.ylabel('Target predicted')\n",
    "    plt.xlabel('True Target')\n",
    "    plt.title(model_name)\n",
    "    \n",
    "    pos_x = y_actual.max() * 0.60\n",
    "    pos_y = y_pred.max() * 0.90\n",
    "    \n",
    "    plt.text(pos_x, pos_y, r'$RMSE=%.2f, R^2$=%.2f, MAE=%.2f' % (np.sqrt(mean_squared_error(y_actual, y_pred)), \n",
    "                                              r2_score(y_actual, y_pred), \n",
    "                                              mean_absolute_error(y_actual, y_pred)))\n",
    "    plt.savefig('./scatter_results-{}.png'.format(model_name))\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build our first model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-09T07:25:17.318585Z",
     "start_time": "2019-04-09T07:24:48.923245Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rmse: 69.26025167803729 - mae: 32.868402918524524 - r2: 0.5332219311345148\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "# Train model\n",
    "rfp = RandomForestRegressor(random_state=0, n_estimators=100)\n",
    "model = rfp.fit(train_x, train_y)\n",
    "\n",
    "\n",
    "pred_test = model.predict(test_x)\n",
    "\n",
    "print('rmse: {} - mae: {} - r2: {}'.format(*eval_metrics(test_y, pred_test)))\n",
    "scatter_plot_result(test_y, pred_test, 'RandomForest')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To see scatter plot result: [see_plot](./scatter_results-RandomForest.png)\n",
    "\n",
    "-> `Retrain your model with another set of parameters and compare results`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build a second model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Often, we use a second model in order to challenge the first one..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-09T07:26:31.035815Z",
     "start_time": "2019-04-09T07:26:30.402044Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rmse: 93.26987572150462 - mae: 52.84971226579352 - r2: 0.15350361381773747\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import ElasticNet\n",
    "from sklearn.preprocessing import QuantileTransformer, quantile_transform\n",
    "\n",
    "\n",
    "# Train model\n",
    "lr = ElasticNet(random_state=0, alpha=0.5, l1_ratio=0.2)\n",
    "model = lr.fit(train_x, train_y)\n",
    "\n",
    "\n",
    "pred_test = model.predict(test_x)\n",
    "\n",
    "print('rmse: {} - mae: {} - r2: {}'.format(*eval_metrics(test_y, pred_test)))\n",
    "scatter_plot_result(test_y, pred_test, 'ElasticNet')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To see scatter plot result: [see_plot](./scatter_results-ElasticNet.png)\n",
    "\n",
    "-> `Retrain your model with another set of parameters and compare results`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Utility of ML Flow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this point you may want to draw more visualizations to compare your models :\n",
    "    * performance, \n",
    "    * feature importance\n",
    "    * other metrics\n",
    "\n",
    "You understand that we will have do this process **EVERY TIME**, to compare or analyse any model or ML code. \n",
    "\n",
    "Also, **if your data change**, your metrics can change. It would be great to have the history of the data ATTACHED to the code's history\n",
    "\n",
    "__*This is where Tracking with MLflow is useful*__\n",
    "\n",
    "Same exercise in `train.py`. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 - MLflow [Tracking](https://mlflow.org/docs/latest/tracking.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.compose import TransformedTargetRegressor\n",
    "\n",
    "# If you wish to try on classification problem\n",
    "def log_metrics_classification(y_true, y_prediction):\n",
    "    report = classification_report(y_true, y_prediction, output_dict=True)\n",
    "    for class_ in ['0', '1']:\n",
    "        for metric in report[class_]:\n",
    "            log_name = class_ + '_' + metric\n",
    "            # insert your code here ~ 1 line\n",
    "         \n",
    "        \n",
    "def log_metrics_regression(y_true, y_prediction):\n",
    "    rmse, mae, r2 = eval_metrics(y_true, y_prediction)\n",
    "    # log metrics here ~ 3 lines\n",
    "\n",
    "def set_mlfow_experiment(experiment_name):\n",
    "    experiment_name = 'Default' if experiment_name is None else experiment_name\n",
    "    mlflow.set_experiment(experiment_name)\n",
    "\n",
    "\n",
    "def run_experiment_elasticnet(df, alpha, l1_ratio, experiment_name=None):\n",
    "    # set exeperiment here ~ 1 line\n",
    "    set_mlfow_experiment(experiment_name)\n",
    "    \n",
    "    # Split data\n",
    "    train, test = train_test_split(df)\n",
    "    \n",
    "    train_x = train.drop([target_column], axis=1)\n",
    "    test_x = test.drop([target_column], axis=1)\n",
    "    train_y = train[target_column]\n",
    "    test_y = test[target_column]\n",
    "    \n",
    "    with mlflow.start_run():\n",
    "        print(\"Running with alpha: {} - l1_ratio: {}\".format(alpha, l1_ratio))\n",
    "\n",
    "        # fit models\n",
    "        lr = ElasticNet(random_state=0, alpha=alpha, l1_ratio=l1_ratio)\n",
    "        lr.fit(train_x, train_y)\n",
    "\n",
    "        prediction_test = lr.predict(test_x)\n",
    "\n",
    "        # log parameters\n",
    "        # Your code here ~ 2 lines\n",
    "\n",
    "        # log artifact\n",
    "        scatter_name = './scatter_results-ElasticNet.png'\n",
    "        # save scatter plot as artifact here ~ 2 lines (1 to create the file, 1 to save as artifact)\n",
    "\n",
    "        # log metrics\n",
    "        log_metrics_regression(test_y, prediction_test)\n",
    "\n",
    "        # log sklearn model\n",
    "        # log the sklearn model here  ~ 1 line\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running with alpha: 0.1 - l1_ratio: 0.1\n",
      "Running with alpha: 0.1 - l1_ratio: 0.30000000000000004\n",
      "Running with alpha: 0.1 - l1_ratio: 0.5000000000000001\n",
      "Running with alpha: 0.1 - l1_ratio: 0.7000000000000001\n",
      "Running with alpha: 0.1 - l1_ratio: 0.9000000000000001\n"
     ]
    }
   ],
   "source": [
    "# play yourself with parameters\n",
    "# ! both parameters have min 0 and max 1 ! \n",
    "\n",
    "\n",
    "# Remove break to see all runs\n",
    "for alpha in np.arange(0.1, 1, 0.2):\n",
    "    for l1_ratio in np.arange(0.1, 1, 0.2):\n",
    "        run_experiment_elasticnet(df_all, alpha, l1_ratio)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 - MLflow [Projects](https://mlflow.org/docs/latest/projects.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Now we will \"package\" our project as an MLflow project:**\n",
    "* MLflow Projects are just a convention for organizing and describing your code\n",
    "* Each project is simply a directory of files, or a Git repository, containing your code\n",
    "* MLflow can run some projects based on a convention for placing files in this directory but you can describe your project in more detail by adding a `MLproject file, which is a YAML formatted text` file\n",
    "\n",
    "**We will make our `MLproject file` and define:**\n",
    "* Name\n",
    "* Entry point (you can define several entry point : etl -> train -> test, but here we just have the main entry point)\n",
    "* (Environment is optional, see documentation for more information)\n",
    "\n",
    "\n",
    "-> open it: [MLproject file](./MLproject)\n",
    "\n",
    "\n",
    "**Once you finished your MLproject file**\n",
    "The following command runs your project by read your MLproject file on your local system.\n",
    "\n",
    "```bash \n",
    "~$ mlflow run .\n",
    "```\n",
    "\n",
    "\n",
    "\n",
    "**What if you want to change your code, push it on a remote repo and test it with its git hash ?**\n",
    "```bash \n",
    "~$ mlflow run git@github.com:thomasOpenvalue/workshop-mlflow.git --version=84295be...\n",
    "```\n",
    "\n",
    "**more details**:\n",
    "```bash\n",
    "~$ mlflow run --help\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 - MLflow [Models](https://mlflow.org/docs/latest/models.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "During your runs, you saved/logged your models. Each model is attached to a run and you can see it in your MLflow UI by clicking on a run.\n",
    "\n",
    "You can re-use a given model or serve it. MLflow allows you to use a lot of model type like sagemaker models, sklearn models, keras models.\n",
    "Also you can use the Model API as follow.\n",
    "\n",
    "You we'll need to choose a **path** (if you used mlflow.save_model -> the same used path. If you used mlflow.log_model -> the name you gave for the log) and the **run_id** (choose a run in your UI)\n",
    "\n",
    "for more details : [MLflow Model API](https://mlflow.org/docs/latest/models.html#model-api)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/fontaine/anaconda3/envs/workshop-mlflow/lib/python3.7/site-packages/sklearn/base.py:253: UserWarning: Trying to unpickle estimator ElasticNet from version 0.19.1 when using version 0.20.3. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n"
     ]
    }
   ],
   "source": [
    "import mlflow.sklearn\n",
    "\n",
    "sk_model = mlflow.sklearn.load_model(path=\"elastic_net\", run_id=\"2cb....\")\n",
    "\n",
    "pred_test = sk_model.predict(test_x)\n",
    "\n",
    "print('rmse: {} - mae: {} - r2: {}'.format(*eval_metrics(test_y, pred_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
